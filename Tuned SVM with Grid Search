# -*- coding: utf-8 -*-
"""
Created on Sat Jan 18 15:48:56 2020

@author: Mohammad Derakhshi

"""
import pandas as pd
from sklearn import preprocessing, metrics
from sklearn.svm import SVC
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.model_selection import GridSearchCV


def load_data(data_directory, file_name):
    '''
    This function reads the dataset of file_name from the data_directory, 
    splits the content of each documents into labels and content, and finally, 
    returns the preprocessed data.
    '''

    
    data = open(data_directory + file_name, encoding="utf8")

    labels, texts = [], []
    for line in data:
        content = line.rstrip('\n')
        content = content.split("@"*10)
        labels.append(content[0])
        texts.append(content[1])
    
    data.close()
    return labels, texts



def feature_extraction(feature_extraction_type):
    '''
    This function extracts features of the loaded datasets
    '''
    
    if feature_extraction_type == 'count_vectors':      
        # Converting the text documents to a matrix of token counts
        count_vectorizer = CountVectorizer(analyzer='word', token_pattern=r'\w{1,}')
        count_vectorizer.fit(data_frame['text'])
        xtrain_vector = count_vectorizer.transform(train_x)
        xtest_vector = count_vectorizer.transform(test_x)
        
    elif feature_extraction_type == 'tfidf':
        # Converting the text documents to a matrix of TF-IDF features.
        tfidf_vectorizer = TfidfVectorizer(analyzer='word', token_pattern=r'\w{1,}', 
                                           max_features=80000)
        tfidf_vectorizer.fit(data_frame['text'])
        xtrain_vector =  tfidf_vectorizer.transform(train_x)
        xtest_vector =  tfidf_vectorizer.transform(test_x)
        
    elif feature_extraction_type == 'unigram':
        # Unigram level tf-idf
        tfidf_vectorizer_unigram = TfidfVectorizer(analyzer='word', 
                                                   token_pattern=r'\w{1,}', 
                                             ngram_range=(1,1), max_features=80000)
        tfidf_vectorizer_unigram.fit(data_frame['text'])
        xtrain_vector = tfidf_vectorizer_unigram.transform(train_x)
        xtest_vector = tfidf_vectorizer_unigram.transform(test_x)
        
    elif feature_extraction_type == 'bigram':
        # Bigram level tf-idf
        tfidf_vectorizer_bigram = TfidfVectorizer(analyzer='word', token_pattern=r'\w{1,}', 
                                     ngram_range=(2,2), max_features=80000)
        tfidf_vectorizer_bigram.fit(data_frame['text'])
        xtrain_vector = tfidf_vectorizer_bigram.transform(train_x)
        xtest_vector = tfidf_vectorizer_bigram.transform(test_x)
        
    else:
        # both Unigram and bigrams level tf-idf
        tfidf_vectorizer_uni_and_bigram = TfidfVectorizer(analyzer='word', 
                                                          token_pattern=r'\w{1,}', 
                                             ngram_range=(1,2), max_features=80000)
        tfidf_vectorizer_uni_and_bigram.fit(data_frame['text'])
        xtrain_vector = tfidf_vectorizer_uni_and_bigram.transform(train_x)
        xtest_vector = tfidf_vectorizer_uni_and_bigram.transform(test_x)
        
    return xtrain_vector, xtest_vector



def parameter_selection(classifier_model, classifier_parameters, feature_vector, 
                    label_vector, number_folds):
    '''
    This function determines the optimal level of a classifier (svm, naive bayze)
    and returns the optimla classifier
    '''
    
    grid_search = GridSearchCV(classifier_model, classifier_parameters, 
                               cv=number_folds)
    
    grid_search.fit(feature_vector, label_vector)
    
    print("The optimal level of the chosen classifier's paramters are :")
    print(grid_search.best_params_)
    print()

    return grid_search.best_estimator_





def model_evaluation(estimator, feature_vector, label_vector):
    '''
    This method evaluates the model performance on the test set and returns
    the precision, recall, F1-score metrics
    '''
    
    predicted_labels = estimator.predict(feature_vector)
    
    evaluated_metrics = metrics.classification_report(label_vector, predicted_labels)
    print(evaluated_metrics)
    
    return evaluated_metrics


if __name__=="__main__":
    
    
    
    path= "G:\\Python Scripts_old\\AI project\\"
    train_y, train_x= load_data(path, 'HAM-Train.txt')
    test_y, test_x= load_data(path, 'HAM-Test.txt')

    data_frame = pd.DataFrame()
    data_frame['text'], data_frame['label']= train_x, train_y
    
    data_frame1 = pd.DataFrame()
    data_frame1['text'], data_frame1['label']= test_x, test_y
    
    data_frame.append(data_frame1)

    encoder = preprocessing.LabelEncoder()
    train_y = encoder.fit_transform(train_y)
    test_y = encoder.fit_transform(test_y)
    
    feature_types = ['count_vectors', 'tfidf', 'unigram', 'bigram', 'both']
    train_features = {}
    test_features = {}
    
    for feature_type in feature_types:
        train_features[feature_type], test_features[feature_type] = feature_extraction(feature_type)
    
    

    parameter_tuning = False
    tuned_estimators= {}
    
    if parameter_tuning:
        
    
        #learning based on SVM model for all types of extraxted features 
        classifier = SVC()
        kernels = ['poly', 'rbf']
        Cs = [100, 10, 1.0, 0.1, 0.01]
        gammas = [0.001, 0.01, 1]
        
        classifier_paramters = dict(kernel=kernels, C=Cs, gamma=gammas)
        nfolds = 7
        
        
        for feature_type in feature_types:
            print()
            print("------ Here is the launch of grid search for SVM in the case of %s------" %feature_type)
            print()            
            
            tuned_estimators[feature_type] = parameter_selection(classifier, classifier_paramters, 
                            train_features[feature_type], train_y, nfolds)
        
            print()
        
            model_evaluation(tuned_estimators[feature_type], test_features[feature_type], test_y)
            print()

    else:
        print()
        
        kernels = ['poly', 'rbf']
        Cs = [100, 10, 1.0, 0.1, 0.01]
        gammas = [0.001, 0.01, 1]
        
        tuned_parameters = {
                "count_vectors":[kernels[0], Cs[2], gammas[1]],
                "tfidf":[kernels[1], Cs[0], gammas[2]],
                "unigram":[kernels[1], Cs[0], gammas[2]],
                "bigram":[kernels[1], Cs[0], gammas[2]],
                "both":[kernels[1], Cs[0], gammas[2]]}
        
        
        for feature_type in feature_types:
            
            
            print()
            print("------ Here is the evalation of the model in the case of %s------" %feature_type)
            print()            
            
            tuned_estimators[feature_type]=SVC(
                    kernel=tuned_parameters[feature_type][0],
                    C=tuned_parameters[feature_type][1],
                    gamma=tuned_parameters[feature_type][2])
            
            tuned_estimators[feature_type].fit(train_features[feature_type], train_y)
            
            
            model_evaluation(tuned_estimators[feature_type], test_features[feature_type], test_y)
            
            
            
            
            
